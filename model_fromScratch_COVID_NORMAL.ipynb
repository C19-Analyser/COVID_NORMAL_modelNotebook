{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle from scratch : classification binaire COVID / SAIN (NORMAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des modules necessaires\n",
    "\n",
    "import os\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing.image import load_img,img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/VALIDATION/COVID'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-86e1e66a2444>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mImageTRAINNORMAL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/TRAIN/NORMAL'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mImageVALIDATIONCOVID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/VALIDATION/COVID'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mImageVALIDATIONNORMAL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/VALIDATION/NORMAL'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/VALIDATION/COVID'"
     ]
    }
   ],
   "source": [
    "# On declare les chemins vers les donnees :\n",
    "\n",
    "Image = 'Data'\n",
    "        \n",
    "train_data_dir = 'Data/TRAIN'\n",
    "validation_data_dir = 'Data/VALIDATION'\n",
    "test_data_dir = 'Data/TEST'\n",
    "\n",
    "# Dimmension et path :\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "ImageTRAINCOVID = os.listdir(Image + '/TRAIN/COVID')\n",
    "ImageTRAINNORMAL = os.listdir(Image + '/TRAIN/NORMAL')\n",
    "\n",
    "ImageVALIDATIONCOVID = os.listdir(Image + '/VALIDATION/COVID')\n",
    "ImageVALIDATIONNORMAL = os.listdir(Image + '/VALIDATION/NORMAL')\n",
    "\n",
    "ImageTESTCOVID = os.listdir(Image + '/TEST/COVID')\n",
    "ImageTESTNORMAL = os.listdir(Image + '/TEST/NORMAL')\n",
    "\n",
    "print('Il y a ' + str(len(ImageTRAINCOVID)) + ' images d\\'entrainement de patient covid.') \n",
    "print('Il y a ' + str(len(ImageTRAINNORMAL)) + ' images d\\'entrainement de patient non-covid.') \n",
    "print('Il y a ' + str(len(ImageVALIDATIONCOVID)) + ' images de validation de patient covid.') \n",
    "print('Il y a ' + str(len(ImageVALIDATIONNORMAL)) + ' images de validation de patient non-covid.') \n",
    "print('Il y a ' + str(len(ImageTESTCOVID)) + ' images test de patient covid.') \n",
    "print('Il y a ' + str(len(ImageTESTNORMAL)) + ' images test de patient non-covid.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de 6 exemples en 2 lignes et 3 colonnes pour chaque classe :\n",
    "\n",
    "# TRAIN :\n",
    "\n",
    "print(\"TRAIN COVID\")\n",
    "\n",
    "\n",
    "# COVID  :\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    randomImageTRAINCOVID = random.choice(os.listdir(train_data_dir + '/COVID'))\n",
    "    plt.imshow(plt.imread(os.path.join( train_data_dir +'/COVID',randomImageTRAINCOVID)), cmap='gray')\n",
    "    plt.title(randomImageTRAINCOVID)\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "print(\"VALIDATION COVID\")\n",
    "# COVID  :\n",
    "plt.figure(figsize=(20,10))\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    randomImageTESTCOVID = random.choice(os.listdir(validation_data_dir + '/COVID'))\n",
    "    plt.imshow(plt.imread(os.path.join( validation_data_dir +'/COVID',randomImageTESTCOVID)), cmap='gray')\n",
    "    plt.title(randomImageTESTCOVID)\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "print(\"TRAIN NORMAL\")\n",
    "# NORMAL :\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    randomImageTRAINNORMAL = random.choice(os.listdir(train_data_dir + '/NORMAL'))\n",
    "    plt.imshow(plt.imread(os.path.join( train_data_dir +'/NORMAL',randomImageTRAINNORMAL)), cmap='gray')\n",
    "    plt.title(randomImageTRAINNORMAL)\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "\n",
    "# TEST:\n",
    "\n",
    "print(\"VALIDATION NORMAL\")\n",
    "\n",
    "# NORMAL :\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    randomImageTESTNORMAL = random.choice(os.listdir(validation_data_dir + '/NORMAL'))\n",
    "    plt.imshow(plt.imread(os.path.join( validation_data_dir +'/NORMAL',randomImageTESTNORMAL)), cmap='gray')\n",
    "    plt.title(randomImageTESTNORMAL)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1726 images belonging to 2 classes.\n",
      "Found 433 images belonging to 2 classes.\n",
      "Found 1560 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing :\n",
    "\n",
    "# On rescale les images :\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# On definit la batch size :\n",
    "\n",
    "batch_size = 32 \n",
    "\n",
    "# On prepare les tableaux de donnees depuis les images :\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 222, 222, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 109, 109, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 109, 109, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 52, 52, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 52, 52, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 43264)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                2768960   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 2,797,665\n",
      "Trainable params: 2,797,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# On definit l'architecture du model :\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, (3, 3), input_shape=(img_width, img_height,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# On compile le modeles :\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# On affiche le model :\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On definit les parametres pour l'entrainement :\n",
    "epochs = 100\n",
    "train_samples = 1726\n",
    "validation_samples = 433\n",
    "test_samples = 1560\n",
    "\n",
    "# On definit les callbacks : \n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss',mode='min',patience = 10,restore_best_weights=True,),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f84ee51a582c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Entrainement du modele :\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m historique = model.fit_generator(\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_samples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Entrainement du modele :\n",
    "\n",
    "historique = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        callbacks = my_callbacks,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_samples// batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'historique' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-82c53032830d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mn_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistorique\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"la generation optimale est : \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'historique' is not defined"
     ]
    }
   ],
   "source": [
    "n_epochs = len(historique.history['loss'])\n",
    "GenOptimale = n_epochs-10\n",
    "print(\"la generation optimale est : \",GenOptimale)\n",
    "model.save_weights('models/Weights/scratch_224_224_'+str(GenOptimale)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testImage(path):\n",
    "    img = load_img(path, target_size=(224,224))\n",
    "    img = img_to_array(img)\n",
    "    img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n",
    "    y = model.predict(img)\n",
    "    return y[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03264130804833325, 0.988438]\n",
      "[0.093414556601264, 0.987196]\n"
     ]
    }
   ],
   "source": [
    "# On evalue le modele sur les donnes de validation :\n",
    "\n",
    "resultValidation = model.evaluate_generator(validation_generator, validation_samples)\n",
    "\n",
    "# On evalue le modele sur les donnes de test :\n",
    "\n",
    "resultTest = model.evaluate_generator(test_generator, test_samples)\n",
    "\n",
    "# On test quelque image aleatoirement choisis :\n",
    "\n",
    "trueCovidDiagnostic = 0\n",
    "trueNormalDiagnostic = 0\n",
    "falseCovidDiagnostic = 0\n",
    "falseNormalDiagnostic = 0\n",
    "\n",
    "for i in range(100):\n",
    "    if random.randint(1,2) == 1:\n",
    "        index = random.randint(0,len(ImageTESTCOVID))\n",
    "        result = testImage(ImageTESTCOVID[index])\n",
    "        if result == 0:\n",
    "            trueCovidDiagnostic = trueCovidDiagnostic+1\n",
    "        else:\n",
    "            falseNormalDiagnostic = falseNormalDiagnostic+1\n",
    "    else:\n",
    "        index = random.randint(0,len(ImageTESTNORMAL))\n",
    "        result = testImage(ImageTESTNORMAL[index])\n",
    "        if result == 0:\n",
    "            trueNormalDiagnostic = trueNormalDiagnostic+1\n",
    "        else:\n",
    "            falseCovidDiagnostic = falseCovidDiagnostic+1\n",
    "            \n",
    "true = trueCovidDiagnostic + trueNormalDiagnostic\n",
    "# Visualisation de l'image puis test puis affichage du resulat\n",
    "    \n",
    "print(resultValidation)\n",
    "print(resultTest)\n",
    "\n",
    "print('on a testé aleatoirement 100 images du set de test.')\n",
    "print('taux de succés général :',true)\n",
    "print('taux de bon diagnostic Covid :',trueCovidDiagnostic)\n",
    "print('taux de bon diagnostic Normal :',trueNormalDiagnostic)\n",
    "print('taux de faux covid :',falseCovidDiagnostic)\n",
    "print('taux de faux normal :',falseNormalDiagnostic)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: models/scratchFull_10G_224_224/assets\n"
     ]
    }
   ],
   "source": [
    "# On enregistre l'historique et les poids :\n",
    "\n",
    "model.save_weights('models/scratch_10G_224_224.h5')\n",
    "\n",
    "np.save('models/historique_scratch_224_224_10G_Baudouin.npy',historique.history)\n",
    "\n",
    "model.save('models/scratchFull_10G_224_224')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On instencie notre objet ImageDataGenerator\n",
    "\n",
    "MonPetitGenerateur = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        zoom_range=0.15,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.15,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode=\"nearest\", cval=125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On stock les images que l'on veut augmenter\n",
    "\n",
    "image_directory = 'Data/TO-AUGMENTED/COVID/'\n",
    "image_directory2 = 'Data/TO-AUGMENTED/NORMAL/'\n",
    "SIZE = 500\n",
    "datasetCovid = []\n",
    "datasetNormal = []\n",
    "\n",
    "my_images = os.listdir(image_directory)\n",
    "for i, image_name in enumerate(my_images):\n",
    "    if (image_name.split('.')[1] == 'jpg'):\n",
    "        image = load_img(image_directory + image_name,target_size = (224,224))\n",
    "        image = img_to_array(image)\n",
    "        image = image.reshape((image.shape[0], image.shape[1], image.shape[2]))\n",
    "        datasetCovid.append(image)\n",
    "x = np.array(datasetCovid)\n",
    "\n",
    "my_images2 = os.listdir(image_directory2)\n",
    "for i, image_name in enumerate(my_images2):\n",
    "    if (image_name.split('.')[1] == 'jpg'):\n",
    "        image2 = load_img(image_directory2 + image_name,target_size = (224,224))\n",
    "        image2 = img_to_array(image2)\n",
    "        image2 = image2.reshape((image2.shape[0], image2.shape[1], image2.shape[2]))\n",
    "        datasetNormal.append(image2)\n",
    "y = np.array(datasetNormal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On augmente et on stock les nouvelles images\n",
    "\n",
    "i = 0\n",
    "for batch in MonPetitGenerateur.flow(x, batch_size=32,  \n",
    "                          save_to_dir='Data/AUGMENTED/COVID-AUGMENTED', \n",
    "                          save_prefix='aug', \n",
    "                          save_format='png'):\n",
    "    i += 1\n",
    "    if i > 19:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for batch in MonPetitGenerateur.flow(y, batch_size=32,  \n",
    "                          save_to_dir='Data/AUGMENTED/NORMAL-AUGMENTED', \n",
    "                          save_prefix='aug', \n",
    "                          save_format='png'):\n",
    "    i += 1\n",
    "    if i > 19:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On declare les chemins vers les nouvelles donnees :\n",
    "Image = 'data'\n",
    "train_data_dir = 'Data/AUGMENTED'\n",
    "validation_data_dir = 'Data/TEST'\n",
    "\n",
    "# On declare les dimensions pour les images (224,224) :\n",
    "\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "# On liste et stocke les chemins des images :\n",
    "\n",
    "ImageTRAINCOVID = os.listdir(Image + '/AUGMENTED/COVID-AUGMENTED')\n",
    "ImageTRAINNORMAL = os.listdir(Image + '/AUGMENTED/NORMAL-AUGMENTED')\n",
    "\n",
    "ImageTESTCOVID = os.listdir(Image + '/TEST/COVID')\n",
    "ImageTESTNORMAL = os.listdir(Image + '/TEST/NORMAL')\n",
    "\n",
    "# On affiche le nombre d'image trouve :\n",
    "\n",
    "print('Il y a ' + str(len(ImageTRAINCOVID)) + ' images d\\'entrainement de patient covid.') \n",
    "print('Il y a ' + str(len(ImageTRAINNORMAL)) + ' images d\\'entrainement de patient non-covid.') \n",
    "print('Il y a ' + str(len(ImageTESTCOVID)) + ' images test de patient covid.') \n",
    "print('Il y a ' + str(len(ImageTESTNORMAL)) + ' images test de patient non-covid.') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On rescale les images :\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# On definit la batch size :\n",
    "\n",
    "batch_size = 32 \n",
    "\n",
    "# On prepare les tableaux de donnees depuis les images :\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On Re-definit les paramétres pour l'entrainement :\n",
    "\n",
    "epochs = 4\n",
    "train_samples = 160\n",
    "validation_samples = 1200\n",
    "test_samples = 1200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-Entrainement du modele :\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_samples// batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On evalue le modele sur les donnes de validation :\n",
    "\n",
    "resultValidation = model.evaluate_generator(validation_generator, validation_samples)\n",
    "\n",
    "# On evalue le modele sur les donnes de test :\n",
    "\n",
    "resultTest = model.evaluate_generator(test_generator, test_samples)\n",
    "\n",
    "resultExemple = testImage(\"Data/EXEMPLE/COVID1\")\n",
    "\n",
    "    # Visualisation de l'image puis test puis affichage du resulat\n",
    "    \n",
    "print(resultValidation)\n",
    "print(resultTest)\n",
    "print(resultExemple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On enregistre l'historique et les poids :\n",
    "\n",
    "np.save('models/historique_scratch_224_224_'+str(GenOptimale)+'.npy',historique.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fin du programme ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
