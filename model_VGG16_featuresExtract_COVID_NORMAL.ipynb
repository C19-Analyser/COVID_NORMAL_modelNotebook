{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle pre-entrainer VGG16 : classification binaire COVID / SAIN (NORMAL) par extraction de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des modules necessaire :\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 460 images d'entrainement de patient covid.\n",
      "Il y a 1266 images d'entrainement de patient non-covid.\n",
      "Il y a 116 images test de patient covid.\n",
      "Il y a 317 images test de patient non-covid.\n"
     ]
    }
   ],
   "source": [
    "# On declare les chemins vers les donnees :\n",
    "\n",
    "trainDir = 'Data/TRAIN'\n",
    "validationDir = 'Data/TEST'\n",
    " \n",
    "# On declare les dimensions pour les images (224,224) :\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "# On liste et stocke les chemins des images :\n",
    "ImageTRAINCOVID = os.listdir(trainDir + '/COVID')\n",
    "ImageTRAINNORMAL = os.listdir(trainDir + '/NORMAL')\n",
    "\n",
    "ImageTESTCOVID = os.listdir(validationDir + '/COVID')\n",
    "ImageTESTNORMAL = os.listdir(validationDir + '/NORMAL')\n",
    "\n",
    "# On affiche le nombre d'image trouve :\n",
    "print('Il y a ' + str(len(ImageTRAINCOVID)) + ' images d\\'entrainement de patient covid.') \n",
    "print('Il y a ' + str(len(ImageTRAINNORMAL)) + ' images d\\'entrainement de patient non-covid.') \n",
    "print('Il y a ' + str(len(ImageTESTCOVID)) + ' images test de patient covid.') \n",
    "print('Il y a ' + str(len(ImageTESTNORMAL)) + ' images test de patient non-covid.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de 6 exemples en 2 lignes et 3 colonnes pour chaque classe :\n",
    "\n",
    "    # Chourouk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1726 images belonging to 2 classes.\n",
      "Found 433 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing :\n",
    "# On rescale les images :\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# On definit la batch size :\n",
    "batch_size = 32\n",
    "\n",
    "# On prepare les tableaux de donnees depuis les images :\n",
    "train_generator_bottleneck = datagen.flow_from_directory(\n",
    "        trainDir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "\n",
    "validation_generator_bottleneck = datagen.flow_from_directory(\n",
    "        validationDir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement de VGG16 sans la partie fully-connected avec le reseau convolutif entrainer sur imagenet :\n",
    "\n",
    "model_vgg = applications.VGG16(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On utilse le model VGG16 pour extraire les features de nos images \n",
    "# (on fait recupere la sortie du reseau convolutionnel) :\n",
    "train_features = model_vgg.predict_generator(train_generator_bottleneck, 1726 // batch_size)\n",
    "\n",
    "validation_features = model_vgg.predict_generator(validation_generator_bottleneck, 433 // batch_size)\n",
    "\n",
    "# L'opération étant longue on enregistre les features obtenus :\n",
    "np.save(open('models/trainFeatures_VGG16_AllData.npy', 'wb'), train_features) # ecriture en binaire necessaire\n",
    "np.save(open('models/validationFeatures_VGG16_AllData.npy', 'wb'), validation_features) # Idem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si l'operation à deja été effectuer on charge les features :\n",
    "\n",
    "train_features = np.load(open('models/trainFeatures_VGG16_AllData.npy', 'rb'))\n",
    "\n",
    "validation_features = np.load(open('models/validationFeatures_VGG16_AllData.npy', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On definit les labels :\n",
    "\n",
    "train_labels = np.array([0] * 448 + [1] * 1248)\n",
    "\n",
    "validation_labels = np.array([0] * 116 + [1] * 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On peut maintenant tester plusieurs couches fully-connected à partir de ce modele :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                1605696   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,605,761\n",
      "Trainable params: 1,605,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Premier modele : \n",
    "model_top1 = Sequential()\n",
    "model_top1.add(Flatten(input_shape=train_features.shape[1:]))\n",
    "model_top1.add(Dense(64, activation='relu'))\n",
    "model_top1.add(Dropout(0.5))\n",
    "model_top1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# On compile :\n",
    "model_top1.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# On affiche :\n",
    "model_top1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               3211392   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 3,211,521\n",
      "Trainable params: 3,211,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Second modele :\n",
    "model_top2 = Sequential()\n",
    "model_top2.add(Flatten(input_shape=train_features.shape[1:]))\n",
    "model_top2.add(Dense(128, activation='relu'))\n",
    "model_top2.add(Dropout(0.5))\n",
    "model_top2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# On compile :\n",
    "model_top2.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# On affiche :\n",
    "model_top2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               6422784   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 6,423,041\n",
      "Trainable params: 6,423,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Troisieme modele :\n",
    "model_top3 = Sequential()\n",
    "model_top3.add(Flatten(input_shape=train_features.shape[1:]))\n",
    "model_top3.add(Dense(256, activation='relu'))\n",
    "model_top3.add(Dropout(0.5))\n",
    "model_top3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# On compile :\n",
    "model_top3.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# On affiche :\n",
    "model_top3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On definit les parametres pour l'entrainement :\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1696 samples, validate on 416 samples\n",
      "Epoch 1/10\n",
      "1696/1696 [==============================] - 5s 3ms/sample - loss: 0.3847 - accuracy: 0.8962 - val_loss: 0.1350 - val_accuracy: 0.9495\n",
      "Epoch 2/10\n",
      "1696/1696 [==============================] - 2s 1ms/sample - loss: 0.1134 - accuracy: 0.9670 - val_loss: 0.0961 - val_accuracy: 0.9808\n",
      "Epoch 3/10\n",
      "1696/1696 [==============================] - 2s 1ms/sample - loss: 0.1027 - accuracy: 0.9711 - val_loss: 0.0154 - val_accuracy: 0.9952\n",
      "Epoch 4/10\n",
      "1696/1696 [==============================] - 2s 1ms/sample - loss: 0.0653 - accuracy: 0.9829 - val_loss: 0.0538 - val_accuracy: 0.9736\n",
      "Epoch 5/10\n",
      "1696/1696 [==============================] - 2s 1ms/sample - loss: 0.0783 - accuracy: 0.9823 - val_loss: 0.0184 - val_accuracy: 0.9952\n",
      "Epoch 6/10\n",
      "1696/1696 [==============================] - 3s 2ms/sample - loss: 0.0611 - accuracy: 0.9864 - val_loss: 0.0324 - val_accuracy: 0.9904\n",
      "Epoch 7/10\n",
      "1696/1696 [==============================] - 2s 1ms/sample - loss: 0.0613 - accuracy: 0.9888 - val_loss: 0.0594 - val_accuracy: 0.9832\n",
      "Epoch 8/10\n",
      "1696/1696 [==============================] - 2s 1ms/sample - loss: 0.0589 - accuracy: 0.9882 - val_loss: 0.0101 - val_accuracy: 0.9976\n",
      "Epoch 9/10\n",
      "1696/1696 [==============================] - 2s 1ms/sample - loss: 0.0576 - accuracy: 0.9864 - val_loss: 0.0180 - val_accuracy: 0.9952\n",
      "Epoch 10/10\n",
      "1696/1696 [==============================] - 3s 2ms/sample - loss: 0.0439 - accuracy: 0.9876 - val_loss: 0.0049 - val_accuracy: 0.9976\n"
     ]
    }
   ],
   "source": [
    "# On entraine le premier modèle:\n",
    "\n",
    "historique1 = model_top1.fit(train_features, train_labels,\n",
    "        epochs=epochs, \n",
    "        batch_size=batch_size,\n",
    "        validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1696 samples, validate on 416 samples\n",
      "Epoch 1/10\n",
      "1696/1696 [==============================] - 6s 3ms/sample - loss: 0.5866 - accuracy: 0.9116 - val_loss: 0.3590 - val_accuracy: 0.8990\n",
      "Epoch 2/10\n",
      "1696/1696 [==============================] - 6s 3ms/sample - loss: 0.1030 - accuracy: 0.9752 - val_loss: 0.2682 - val_accuracy: 0.9303\n",
      "Epoch 3/10\n",
      "1696/1696 [==============================] - 5s 3ms/sample - loss: 0.0873 - accuracy: 0.9758 - val_loss: 0.0876 - val_accuracy: 0.9591\n",
      "Epoch 4/10\n",
      "1696/1696 [==============================] - 4s 2ms/sample - loss: 0.0805 - accuracy: 0.9811 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1696/1696 [==============================] - 4s 3ms/sample - loss: 0.0609 - accuracy: 0.9835 - val_loss: 0.0070 - val_accuracy: 0.9952\n",
      "Epoch 6/10\n",
      "1696/1696 [==============================] - 4s 2ms/sample - loss: 0.0603 - accuracy: 0.9853 - val_loss: 0.0296 - val_accuracy: 0.9880\n",
      "Epoch 7/10\n",
      "1696/1696 [==============================] - 4s 2ms/sample - loss: 0.0457 - accuracy: 0.9906 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1696/1696 [==============================] - 4s 2ms/sample - loss: 0.0542 - accuracy: 0.9864 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1696/1696 [==============================] - 4s 2ms/sample - loss: 0.0431 - accuracy: 0.9917 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1696/1696 [==============================] - 4s 3ms/sample - loss: 0.0373 - accuracy: 0.9923 - val_loss: 0.0103 - val_accuracy: 0.9952\n"
     ]
    }
   ],
   "source": [
    "# On entraine le deuxième modèle:\n",
    "historique2 = model_top2.fit(train_features, train_labels,\n",
    "        epochs=epochs, \n",
    "        batch_size=batch_size,\n",
    "        validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1696 samples, validate on 416 samples\n",
      "Epoch 1/10\n",
      "1696/1696 [==============================] - 10s 6ms/sample - loss: 0.7404 - accuracy: 0.9151 - val_loss: 0.2329 - val_accuracy: 0.9399\n",
      "Epoch 2/10\n",
      "1696/1696 [==============================] - 7s 4ms/sample - loss: 0.1320 - accuracy: 0.9658 - val_loss: 0.0181 - val_accuracy: 0.9904\n",
      "Epoch 3/10\n",
      "1696/1696 [==============================] - 7s 4ms/sample - loss: 0.1270 - accuracy: 0.9682 - val_loss: 0.0363 - val_accuracy: 0.9832\n",
      "Epoch 4/10\n",
      "1696/1696 [==============================] - 9s 5ms/sample - loss: 0.1177 - accuracy: 0.9717 - val_loss: 0.0072 - val_accuracy: 0.9976\n",
      "Epoch 5/10\n",
      "1696/1696 [==============================] - 9s 5ms/sample - loss: 0.0761 - accuracy: 0.9788 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1696/1696 [==============================] - 11s 6ms/sample - loss: 0.0725 - accuracy: 0.9829 - val_loss: 0.0398 - val_accuracy: 0.9880\n",
      "Epoch 7/10\n",
      "1696/1696 [==============================] - 10s 6ms/sample - loss: 0.0630 - accuracy: 0.9864 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1696/1696 [==============================] - 9s 5ms/sample - loss: 0.0582 - accuracy: 0.9841 - val_loss: 0.0367 - val_accuracy: 0.9856\n",
      "Epoch 9/10\n",
      "1696/1696 [==============================] - 7s 4ms/sample - loss: 0.0470 - accuracy: 0.9858 - val_loss: 0.0724 - val_accuracy: 0.9736\n",
      "Epoch 10/10\n",
      "1696/1696 [==============================] - 7s 4ms/sample - loss: 0.0395 - accuracy: 0.9923 - val_loss: 0.0032 - val_accuracy: 0.9976\n"
     ]
    }
   ],
   "source": [
    "# On entraine le troisième modèle:\n",
    "historique3 = model_top3.fit(train_features, train_labels,\n",
    "        epochs=epochs, \n",
    "        batch_size=batch_size,\n",
    "        validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de l'entrainement :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416/1 - 0s - loss: 0.0026 - accuracy: 0.9976\n",
      "416/1 - 0s - loss: 0.0052 - accuracy: 0.9952\n",
      "416/1 - 0s - loss: 0.0016 - accuracy: 0.9976\n",
      "[0.004949446385168699, 0.99759614]\n",
      "[0.010339963535211338, 0.9951923]\n",
      "[0.0031635455436091176, 0.99759614]\n"
     ]
    }
   ],
   "source": [
    "# On evalue :\n",
    "\n",
    "# Avec les donnes de validation :\n",
    "eval1 = model_top1.evaluate(validation_features, validation_labels,verbose=2)\n",
    "eval2 = model_top2.evaluate(validation_features, validation_labels,verbose=2)\n",
    "eval3 = model_top3.evaluate(validation_features, validation_labels,verbose=2)\n",
    "\n",
    "# Avec les donnes de test :\n",
    "\n",
    "    # A ajouter\n",
    "\n",
    "# On prend quelques exemples aleatoires :\n",
    "\n",
    "    # on visualise, on test , on affiche :\n",
    "    \n",
    "    # => Chourouk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: FullModels/vgg16_lightTop_224_224_10G/assets\n",
      "INFO:tensorflow:Assets written to: FullModels/vgg16_mediumTop_224_224_10G/assets\n",
      "INFO:tensorflow:Assets written to: FullModels/vgg16_heavyTop_224_224_10G/assets\n"
     ]
    }
   ],
   "source": [
    "# On enregistre le model (eventuel) :\n",
    "model_top1.save_weights('models/vgg16_lightTop_224_224_10G.h5')\n",
    "model_top2.save_weights('models/vgg16_mediumTop_224_224_10G.h5')\n",
    "model_top3.save_weights('models/vgg16_heavyTop_224_224_10G.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
