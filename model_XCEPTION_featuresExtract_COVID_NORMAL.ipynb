{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle pre-entrainer XCEPTION : classification binaire COVID / SAIN (NORMAL) par extraction de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des modules necessaire :\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 401 images d'entrainement de patient covid.\n",
      "Il y a 401 images d'entrainement de patient non-covid.\n",
      "Il y a 102 images test de patient covid.\n",
      "Il y a 102 images test de patient non-covid.\n"
     ]
    }
   ],
   "source": [
    "# On declare les chemins vers les donnees :\n",
    "\n",
    "trainDir = 'Data/TRAIN'\n",
    "validationDir = 'Data/TEST'\n",
    "        \n",
    "# On declare les dimensions pour les images (224,224) :\n",
    "\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "# On liste et stocke les chemins des images :\n",
    "\n",
    "ImageTRAINCOVID = os.listdir(trainDir + '/COVID')\n",
    "ImageTRAINNORMAL = os.listdir(trainDir + '/NORMAL')\n",
    "\n",
    "ImageTESTCOVID = os.listdir(validationDir + '/COVID')\n",
    "ImageTESTNORMAL = os.listdir(validationDir + '/NORMAL')\n",
    "\n",
    "# On affiche le nombre d'image trouve :\n",
    "\n",
    "print('Il y a ' + str(len(ImageTRAINCOVID)) + ' images d\\'entrainement de patient covid.') \n",
    "print('Il y a ' + str(len(ImageTRAINNORMAL)) + ' images d\\'entrainement de patient non-covid.') \n",
    "print('Il y a ' + str(len(ImageTESTCOVID)) + ' images test de patient covid.') \n",
    "print('Il y a ' + str(len(ImageTESTNORMAL)) + ' images test de patient non-covid.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de 6 exemples en 2 lignes et 3 colonnes pour chaque classe :\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 802 images belonging to 2 classes.\n",
      "Found 204 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing :\n",
    "\n",
    "# On rescale les images :\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# On definit la batch size :\n",
    "batch_size = 32\n",
    "\n",
    "# On prepare les tableaux de donnees depuis les images :\n",
    "\n",
    "train_generator_bottleneck = datagen.flow_from_directory(\n",
    "        trainDir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "\n",
    "validation_generator_bottleneck = datagen.flow_from_directory(\n",
    "        validationDir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Guillaume\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 121s 1us/step\n"
     ]
    }
   ],
   "source": [
    "# Chargement de XCEPTION sans la partie fully-connected avec le reseau convolutif :\n",
    "\n",
    "model_XCEPTION = applications.Xception(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On utilse le model XCEPTION pour extraire les features de nos images \n",
    "# (on fait recupere la sortie du reseau convolutionnel) :\n",
    "\n",
    "train_features = model_XCEPTION.predict_generator(train_generator_bottleneck, 802 // batch_size)\n",
    "\n",
    "np.save(open('models/trainFeatures.npy', 'wb'), train_features)\n",
    "\n",
    "validation_features = model_XCEPTION.predict_generator(validation_generator_bottleneck, 204 // batch_size)\n",
    "\n",
    "# L'opération étant longue on enregistre les features obtenus :\n",
    "\n",
    "np.save(open('models/validationFeatures.npy', 'wb'), validation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si l'operation à deja été effectuer on charge les features :\n",
    "\n",
    "train_features = np.load(open('models/trainFeatures.npy', 'rb'))\n",
    "\n",
    "validation_features = np.load(open('models/validationFeatures.npy', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On definit les labels :\n",
    "\n",
    "train_labels = np.array([0] * 400 + [1] * 400)\n",
    "\n",
    "validation_labels = np.array([0] * 96 + [1] * 96)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On peut maintenant tester plusieurs couche fully-connected à partir de ce modele :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Guillaume\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                6422592   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 6,422,657\n",
      "Trainable params: 6,422,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Premier modele : \n",
    "\n",
    "model_top1 = Sequential()\n",
    "model_top1.add(Flatten(input_shape=train_features.shape[1:]))\n",
    "model_top1.add(Dense(64, activation='relu'))\n",
    "model_top1.add(Dropout(0.5))\n",
    "model_top1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# On compile :\n",
    "\n",
    "model_top1.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# On affiche :\n",
    "\n",
    "model_top1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               12845184  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 12,845,313\n",
      "Trainable params: 12,845,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Second modele :\n",
    "\n",
    "model_top2 = Sequential()\n",
    "model_top2.add(Flatten(input_shape=train_features.shape[1:]))\n",
    "model_top2.add(Dense(128, activation='relu'))\n",
    "model_top2.add(Dropout(0.5))\n",
    "model_top2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# On compile :\n",
    "\n",
    "model_top2.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# On affiche :\n",
    "\n",
    "model_top2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               25690368  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 25,690,625\n",
      "Trainable params: 25,690,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Troisieme modele :\n",
    "\n",
    "model_top3 = Sequential()\n",
    "model_top3.add(Flatten(input_shape=train_features.shape[1:]))\n",
    "model_top3.add(Dense(256, activation='relu'))\n",
    "model_top3.add(Dropout(0.5))\n",
    "model_top3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# On compile :\n",
    "\n",
    "model_top3.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# On affiche :\n",
    "\n",
    "model_top3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On definit les parametres pour l'entrainement :\n",
    "\n",
    "epochs = 10\n",
    "train_samples = 802\n",
    "validation_samples = 204"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 192 samples\n",
      "Epoch 1/10\n",
      "800/800 [==============================] - 3s 4ms/sample - loss: 1.1906 - acc: 0.9312 - val_loss: 2.3839 - val_acc: 0.9635\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 3s 3ms/sample - loss: 0.1851 - acc: 0.9887 - val_loss: 1.6964 - val_acc: 0.9479\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 3s 3ms/sample - loss: 0.1757 - acc: 0.9825 - val_loss: 2.1452 - val_acc: 0.9688\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 3s 4ms/sample - loss: 0.2528 - acc: 0.9812 - val_loss: 1.7228 - val_acc: 0.9688\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 3s 4ms/sample - loss: 0.1398 - acc: 0.9875 - val_loss: 1.5176 - val_acc: 0.9635\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 3s 4ms/sample - loss: 0.0665 - acc: 0.9875 - val_loss: 1.9077 - val_acc: 0.9635\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 3s 3ms/sample - loss: 0.0340 - acc: 0.9937 - val_loss: 1.9517 - val_acc: 0.9635\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 3s 4ms/sample - loss: 0.1288 - acc: 0.9862 - val_loss: 1.8237 - val_acc: 0.9583\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 3s 4ms/sample - loss: 0.0302 - acc: 0.9937 - val_loss: 2.0736 - val_acc: 0.9635\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 3s 4ms/sample - loss: 0.0070 - acc: 0.9950 - val_loss: 2.3446 - val_acc: 0.9688\n"
     ]
    }
   ],
   "source": [
    "# On entraine le modèle 1:\n",
    "\n",
    "hystory1 = model_top1.fit(train_features, train_labels,\n",
    "        epochs=epochs, \n",
    "        batch_size=batch_size,\n",
    "        validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 192 samples\n",
      "Epoch 1/10\n",
      "800/800 [==============================] - 6s 7ms/sample - loss: 2.3580 - acc: 0.9400 - val_loss: 4.9403 - val_acc: 0.9583\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 5s 7ms/sample - loss: 0.2091 - acc: 0.9937 - val_loss: 4.0236 - val_acc: 0.9635\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 5s 7ms/sample - loss: 0.3316 - acc: 0.9837 - val_loss: 5.2328 - val_acc: 0.9583\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.4307 - acc: 0.9850 - val_loss: 4.3219 - val_acc: 0.9635\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 0.2095 - acc: 0.9887 - val_loss: 3.9515 - val_acc: 0.9635\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 6s 7ms/sample - loss: 0.1754 - acc: 0.9850 - val_loss: 4.1000 - val_acc: 0.9635\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 5s 7ms/sample - loss: 0.1382 - acc: 0.9937 - val_loss: 3.9078 - val_acc: 0.9583\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 6s 7ms/sample - loss: 0.0157 - acc: 0.9987 - val_loss: 3.5992 - val_acc: 0.9635\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 5s 7ms/sample - loss: 0.1780 - acc: 0.9912 - val_loss: 4.1703 - val_acc: 0.9635\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 5s 6ms/sample - loss: 2.2179e-08 - acc: 1.0000 - val_loss: 4.1675 - val_acc: 0.9635\n"
     ]
    }
   ],
   "source": [
    "# On entraine le modèle 2:\n",
    "\n",
    "hystory2 = model_top2.fit(train_features, train_labels,\n",
    "        epochs=epochs, \n",
    "        batch_size=batch_size,\n",
    "        validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 192 samples\n",
      "Epoch 1/10\n",
      "800/800 [==============================] - 10s 13ms/sample - loss: 2.1112 - acc: 0.9450 - val_loss: 6.7507 - val_acc: 0.9635\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 10s 13ms/sample - loss: 1.6142 - acc: 0.9700 - val_loss: 6.4745 - val_acc: 0.9688\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 10s 12ms/sample - loss: 0.2191 - acc: 0.9950 - val_loss: 7.6351 - val_acc: 0.9323\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 9s 11ms/sample - loss: 0.3828 - acc: 0.9862 - val_loss: 6.5783 - val_acc: 0.9688\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 9s 12ms/sample - loss: 0.4963 - acc: 0.9850 - val_loss: 8.4328 - val_acc: 0.9531\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 10s 12ms/sample - loss: 0.3661 - acc: 0.9925 - val_loss: 6.9093 - val_acc: 0.9635\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 9s 12ms/sample - loss: 0.4071 - acc: 0.9862 - val_loss: 6.1754 - val_acc: 0.9531\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 10s 12ms/sample - loss: 0.0256 - acc: 0.9962 - val_loss: 6.1095 - val_acc: 0.9635\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 9s 12ms/sample - loss: 0.1021 - acc: 0.9925 - val_loss: 6.4293 - val_acc: 0.9635\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 10s 12ms/sample - loss: 0.2167 - acc: 0.9900 - val_loss: 6.8676 - val_acc: 0.9479\n"
     ]
    }
   ],
   "source": [
    "# On entraine le modèle 3:\n",
    "\n",
    "hystory3 = model_top3.fit(train_features, train_labels,\n",
    "        epochs=epochs, \n",
    "        batch_size=batch_size,\n",
    "        validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de l'entrainement :\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/192 - 0s - loss: 2.3446 - acc: 0.9688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.344556995813266, 0.96875]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On evalue le modèle 1:\n",
    "\n",
    "model_top1.evaluate(validation_features, validation_labels,verbose=2)\n",
    "\n",
    "# Avec les donnes de validation :\n",
    "\n",
    "# Avec les donnes de test :\n",
    "\n",
    "# On prend quelques exemples aleatoires :\n",
    "\n",
    "    # on visualise, on test , on affiche :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/192 - 0s - loss: 4.1675 - acc: 0.9635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.167477752688397, 0.9635417]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On evalue le modèle 2:\n",
    "\n",
    "model_top2.evaluate(validation_features, validation_labels,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/192 - 0s - loss: 6.8676 - acc: 0.9479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6.867551585038503, 0.9479167]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On evalue le modèle 3:\n",
    "\n",
    "model_top3.evaluate(validation_features, validation_labels,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation :\n",
    "\n",
    "# On reproduit le processus puis on compare :"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
