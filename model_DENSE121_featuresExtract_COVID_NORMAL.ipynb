{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle pre-entrainer DENSE121 : classification binaire COVID / SAIN (NORMAL) par extraction de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des modules necessaire :\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 401 images d'entrainement de patient covid.\n",
      "Il y a 401 images d'entrainement de patient non-covid.\n",
      "Il y a 101 images test de patient covid.\n",
      "Il y a 101 images test de patient non-covid.\n"
     ]
    }
   ],
   "source": [
    "# On declare les chemins vers les donnees :\n",
    "\n",
    "trainDir = 'Data/TRAIN'\n",
    "validationDir = 'Data/TEST'\n",
    " \n",
    "# On declare les dimensions pour les images (224,224) :\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "# On liste et stocke les chemins des images :\n",
    "ImageTRAINCOVID = os.listdir(trainDir + '/COVID')\n",
    "ImageTRAINNORMAL = os.listdir(trainDir + '/NORMAL')\n",
    "\n",
    "ImageTESTCOVID = os.listdir(validationDir + '/COVID')\n",
    "ImageTESTNORMAL = os.listdir(validationDir + '/NORMAL')\n",
    "\n",
    "# On affiche le nombre d'image trouve :\n",
    "print('Il y a ' + str(len(ImageTRAINCOVID)) + ' images d\\'entrainement de patient covid.') \n",
    "print('Il y a ' + str(len(ImageTRAINNORMAL)) + ' images d\\'entrainement de patient non-covid.') \n",
    "print('Il y a ' + str(len(ImageTESTCOVID)) + ' images test de patient covid.') \n",
    "print('Il y a ' + str(len(ImageTESTNORMAL)) + ' images test de patient non-covid.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de 6 exemples en 2 lignes et 3 colonnes pour chaque classe :\n",
    "\n",
    "# TRAIN :\n",
    "\n",
    "print(\"TRAIN COVID\")\n",
    "\n",
    "\n",
    "# COVID  :\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    randomImageTRAINCOVID = random.choice(os.listdir(trainDir + '/COVID'))\n",
    "    plt.imshow(plt.imread(os.path.join( trainDir +'/COVID',randomImageTRAINCOVID)), cmap='gray')\n",
    "    plt.title(randomImageTRAINCOVID)\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "print(\"TEST COVID\")\n",
    "# COVID  :\n",
    "plt.figure(figsize=(20,10))\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    randomImageTESTCOVID = random.choice(os.listdir(validationDir + '/COVID'))\n",
    "    plt.imshow(plt.imread(os.path.join( validationDir +'/COVID',randomImageTESTCOVID)), cmap='gray')\n",
    "    plt.title(randomImageTESTCOVID)\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "print(\"TRAIN NORMAL\")\n",
    "# NORMAL :\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    randomImageTRAINNORMAL = random.choice(os.listdir(trainDir + '/NORMAL'))\n",
    "    plt.imshow(plt.imread(os.path.join( trainDir +'/NORMAL',randomImageTRAINNORMAL)), cmap='gray')\n",
    "    plt.title(randomImageTRAINNORMAL)\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "\n",
    "# TEST:\n",
    "\n",
    "print(\"TEST NORMAL\")\n",
    "\n",
    "# NORMAL :\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    randomImageTESTNORMAL = random.choice(os.listdir(validationDir + '/NORMAL'))\n",
    "    plt.imshow(plt.imread(os.path.join(validationDir +'/NORMAL',randomImageTESTNORMAL)), cmap='gray')\n",
    "    plt.title(randomImageTESTNORMAL)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 802 images belonging to 2 classes.\n",
      "Found 202 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing :\n",
    "# On rescale les images :\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# On definit la batch size :\n",
    "batch_size = 32\n",
    "\n",
    "# On prepare les tableaux de donnees depuis les images :\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        trainDir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        validationDir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement de DENSE121 sans la partie fully-connected avec le reseau convolutif :\n",
    "\n",
    "model_dense = applications.DenseNet121(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On utilse le model VGG16 pour extraire les features de nos images \n",
    "# (on fait recupere la sortie du reseau convolutionnel) :\n",
    "train_features = model_dense.predict_generator(train_generator, 1726 // batch_size)\n",
    "\n",
    "validation_features = model_dense.predict_generator(validation_generator, 433 // batch_size)\n",
    "\n",
    "# L'opération étant longue on enregistre les features obtenus :\n",
    "np.save(open('models/trainFeatures_DENSE121_AllData.npy', 'wb'), train_features) # ecriture en binaire necessaire\n",
    "np.save(open('models/validationFeatures_DENSE121_AllData.npy', 'wb'), validation_features) # Idem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si l'operation à deja été effectuer on charge les features :\n",
    "\n",
    "train_features = np.load(open('models/trainFeatures_DENSE121_AllData.npy', 'rb'))\n",
    "validation_features = np.load(open('models/validationFeatures_DENSE121_AllData.npy', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On definit les labels :\n",
    "\n",
    "train_labels = np.array([0] * 448 + [1] * 1248)\n",
    "\n",
    "validation_labels = np.array([0] * 116 + [1] * 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On peut maintenat tester plusieurs couches fully-connected à partir de ce modele :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                3211328   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 3,211,393\n",
      "Trainable params: 3,211,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Premier modele : \n",
    "model_top1 = Sequential()\n",
    "model_top1.add(Flatten(input_shape=train_features.shape[1:]))\n",
    "model_top1.add(Dense(64, activation='relu'))\n",
    "model_top1.add(Dropout(0.5))\n",
    "model_top1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# On compile :\n",
    "model_top1.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# On affiche :\n",
    "model_top1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               6422656   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 6,422,785\n",
      "Trainable params: 6,422,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Second modele :\n",
    "model_top2 = Sequential()\n",
    "model_top2.add(Flatten(input_shape=train_features.shape[1:]))\n",
    "model_top2.add(Dense(128, activation='relu'))\n",
    "model_top2.add(Dropout(0.5))\n",
    "model_top2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# On compile :\n",
    "model_top2.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# On affiche :\n",
    "model_top2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               12845312  \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 12,845,569\n",
      "Trainable params: 12,845,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Troisieme modele :\n",
    "model_top3 = Sequential()\n",
    "model_top3.add(Flatten(input_shape=train_features.shape[1:]))\n",
    "model_top3.add(Dense(256, activation='relu'))\n",
    "model_top3.add(Dropout(0.5))\n",
    "model_top3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# On compile :\n",
    "model_top3.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# On affiche :\n",
    "model_top3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On definit les parametres pour l'entrainement :\n",
    "epochs = 100\n",
    "\n",
    "# On definit les callbacks : \n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss',mode='min',patience = 10,restore_best_weights=True,),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1696 samples, validate on 416 samples\n",
      "Epoch 1/100\n",
      "1696/1696 [==============================] - 6s 4ms/sample - loss: 1.2111 - accuracy: 0.9263 - val_loss: 0.0533 - val_accuracy: 0.9904\n",
      "Epoch 2/100\n",
      "1696/1696 [==============================] - 6s 4ms/sample - loss: 0.2366 - accuracy: 0.9617 - val_loss: 0.0160 - val_accuracy: 0.9928\n",
      "Epoch 3/100\n",
      "1696/1696 [==============================] - 7s 4ms/sample - loss: 0.1669 - accuracy: 0.9676 - val_loss: 0.0294 - val_accuracy: 0.9928\n",
      "Epoch 4/100\n",
      "1696/1696 [==============================] - 7s 4ms/sample - loss: 0.1305 - accuracy: 0.9746 - val_loss: 0.0299 - val_accuracy: 0.9928\n",
      "Epoch 5/100\n",
      "1696/1696 [==============================] - 6s 4ms/sample - loss: 0.1196 - accuracy: 0.9764 - val_loss: 0.0191 - val_accuracy: 0.9928\n",
      "Epoch 6/100\n",
      "1696/1696 [==============================] - 7s 4ms/sample - loss: 0.0978 - accuracy: 0.9823 - val_loss: 0.0774 - val_accuracy: 0.9808\n",
      "Epoch 7/100\n",
      "1696/1696 [==============================] - 6s 4ms/sample - loss: 0.0682 - accuracy: 0.9864 - val_loss: 0.0598 - val_accuracy: 0.9928\n",
      "Epoch 8/100\n",
      "1696/1696 [==============================] - 5s 3ms/sample - loss: 0.0574 - accuracy: 0.9858 - val_loss: 0.0646 - val_accuracy: 0.9856\n",
      "Epoch 9/100\n",
      "1696/1696 [==============================] - 5s 3ms/sample - loss: 0.0960 - accuracy: 0.9823 - val_loss: 0.1196 - val_accuracy: 0.9760\n",
      "Epoch 10/100\n",
      "1696/1696 [==============================] - 6s 3ms/sample - loss: 0.0625 - accuracy: 0.9900 - val_loss: 0.0963 - val_accuracy: 0.9784\n",
      "Epoch 11/100\n",
      "1696/1696 [==============================] - 6s 3ms/sample - loss: 0.0591 - accuracy: 0.9882 - val_loss: 0.7979 - val_accuracy: 0.9327\n",
      "Epoch 12/100\n",
      "1696/1696 [==============================] - 5s 3ms/sample - loss: 0.0812 - accuracy: 0.9817 - val_loss: 0.0725 - val_accuracy: 0.9904\n"
     ]
    }
   ],
   "source": [
    "# On entraine le modèle 1 :\n",
    "\n",
    "history1 = model_top1.fit(train_features, train_labels,\n",
    "        epochs=epochs,\n",
    "        callbacks=my_callbacks,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la generation optimale est :  2\n"
     ]
    }
   ],
   "source": [
    "n_epochs = len(history1.history['loss'])\n",
    "print(\"la generation optimale est : \",n_epochs-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1696 samples, validate on 416 samples\n",
      "Epoch 1/100\n",
      "1696/1696 [==============================] - 13s 8ms/sample - loss: 2.6961 - accuracy: 0.9216 - val_loss: 0.0531 - val_accuracy: 0.9880\n",
      "Epoch 2/100\n",
      "1696/1696 [==============================] - 10s 6ms/sample - loss: 0.2511 - accuracy: 0.9587 - val_loss: 0.3645 - val_accuracy: 0.9111\n",
      "Epoch 3/100\n",
      "1696/1696 [==============================] - 11s 7ms/sample - loss: 0.0952 - accuracy: 0.9723 - val_loss: 0.3865 - val_accuracy: 0.9231\n",
      "Epoch 4/100\n",
      "1696/1696 [==============================] - 10s 6ms/sample - loss: 0.1385 - accuracy: 0.9729 - val_loss: 0.0756 - val_accuracy: 0.9832\n",
      "Epoch 5/100\n",
      "1696/1696 [==============================] - 10s 6ms/sample - loss: 0.1002 - accuracy: 0.9788 - val_loss: 0.0570 - val_accuracy: 0.9808\n",
      "Epoch 6/100\n",
      "1696/1696 [==============================] - 14s 8ms/sample - loss: 0.0804 - accuracy: 0.9841 - val_loss: 0.0125 - val_accuracy: 0.9952\n",
      "Epoch 7/100\n",
      "1696/1696 [==============================] - 12s 7ms/sample - loss: 0.0590 - accuracy: 0.9835 - val_loss: 0.1885 - val_accuracy: 0.9567\n",
      "Epoch 8/100\n",
      "1696/1696 [==============================] - 11s 7ms/sample - loss: 0.0903 - accuracy: 0.9864 - val_loss: 0.0475 - val_accuracy: 0.9904\n",
      "Epoch 9/100\n",
      "1696/1696 [==============================] - 12s 7ms/sample - loss: 0.0657 - accuracy: 0.9864 - val_loss: 0.0824 - val_accuracy: 0.9880\n",
      "Epoch 10/100\n",
      "1696/1696 [==============================] - 11s 6ms/sample - loss: 0.0499 - accuracy: 0.9870 - val_loss: 0.0673 - val_accuracy: 0.9928\n",
      "Epoch 11/100\n",
      "1696/1696 [==============================] - 11s 7ms/sample - loss: 0.0359 - accuracy: 0.9923 - val_loss: 0.0263 - val_accuracy: 0.9928\n",
      "Epoch 12/100\n",
      "1696/1696 [==============================] - 11s 7ms/sample - loss: 0.0463 - accuracy: 0.9906 - val_loss: 0.1143 - val_accuracy: 0.9808\n",
      "Epoch 13/100\n",
      "1696/1696 [==============================] - 11s 7ms/sample - loss: 0.0307 - accuracy: 0.9894 - val_loss: 0.0354 - val_accuracy: 0.9952\n",
      "Epoch 14/100\n",
      "1696/1696 [==============================] - 13s 8ms/sample - loss: 0.0397 - accuracy: 0.9906 - val_loss: 0.0226 - val_accuracy: 0.9928\n",
      "Epoch 15/100\n",
      "1696/1696 [==============================] - 12s 7ms/sample - loss: 0.0364 - accuracy: 0.9929 - val_loss: 0.0318 - val_accuracy: 0.9952\n",
      "Epoch 16/100\n",
      "1696/1696 [==============================] - 11s 7ms/sample - loss: 0.0194 - accuracy: 0.9923 - val_loss: 0.0145 - val_accuracy: 0.9928\n"
     ]
    }
   ],
   "source": [
    "# On entraine le modèle 2:\n",
    "\n",
    "history2 = model_top2.fit(train_features, train_labels,\n",
    "        epochs=epochs, \n",
    "        callbacks=my_callbacks,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la generation optimale est :  6\n"
     ]
    }
   ],
   "source": [
    "n_epochs = len(history2.history['loss'])\n",
    "print(\"la generation optimale est : \",n_epochs-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1696 samples, validate on 416 samples\n",
      "Epoch 1/100\n",
      "1696/1696 [==============================] - 23s 14ms/sample - loss: 4.0663 - accuracy: 0.9180 - val_loss: 0.1293 - val_accuracy: 0.9856\n",
      "Epoch 2/100\n",
      "1696/1696 [==============================] - 21s 12ms/sample - loss: 0.4337 - accuracy: 0.9676 - val_loss: 0.1681 - val_accuracy: 0.9856\n",
      "Epoch 3/100\n",
      "1696/1696 [==============================] - 23s 13ms/sample - loss: 0.2291 - accuracy: 0.9735 - val_loss: 0.1108 - val_accuracy: 0.9856\n",
      "Epoch 4/100\n",
      "1696/1696 [==============================] - 23s 13ms/sample - loss: 0.3082 - accuracy: 0.9729 - val_loss: 0.0376 - val_accuracy: 0.9904\n",
      "Epoch 5/100\n",
      "1696/1696 [==============================] - 21s 12ms/sample - loss: 0.1741 - accuracy: 0.9729 - val_loss: 0.0674 - val_accuracy: 0.9904\n",
      "Epoch 6/100\n",
      "1696/1696 [==============================] - 19s 11ms/sample - loss: 0.1356 - accuracy: 0.9817 - val_loss: 0.0250 - val_accuracy: 0.9880\n",
      "Epoch 7/100\n",
      "1696/1696 [==============================] - 19s 11ms/sample - loss: 0.1067 - accuracy: 0.9841 - val_loss: 0.0484 - val_accuracy: 0.9928\n",
      "Epoch 8/100\n",
      "1696/1696 [==============================] - 19s 11ms/sample - loss: 0.0879 - accuracy: 0.9864 - val_loss: 0.2116 - val_accuracy: 0.9760\n",
      "Epoch 9/100\n",
      "1696/1696 [==============================] - 18s 11ms/sample - loss: 0.0782 - accuracy: 0.9876 - val_loss: 0.0416 - val_accuracy: 0.9952\n",
      "Epoch 10/100\n",
      "1696/1696 [==============================] - 20s 12ms/sample - loss: 0.0390 - accuracy: 0.9917 - val_loss: 0.0592 - val_accuracy: 0.9952\n",
      "Epoch 11/100\n",
      "1696/1696 [==============================] - 21s 12ms/sample - loss: 0.0702 - accuracy: 0.9888 - val_loss: 0.0223 - val_accuracy: 0.9952\n",
      "Epoch 12/100\n",
      "1696/1696 [==============================] - 23s 14ms/sample - loss: 0.0567 - accuracy: 0.9894 - val_loss: 0.0243 - val_accuracy: 0.9928\n",
      "Epoch 13/100\n",
      "1696/1696 [==============================] - 18s 11ms/sample - loss: 0.0153 - accuracy: 0.9947 - val_loss: 0.0284 - val_accuracy: 0.9928\n",
      "Epoch 14/100\n",
      "1696/1696 [==============================] - 17s 10ms/sample - loss: 0.0479 - accuracy: 0.9941 - val_loss: 0.0973 - val_accuracy: 0.9832\n",
      "Epoch 15/100\n",
      "1696/1696 [==============================] - 17s 10ms/sample - loss: 0.0378 - accuracy: 0.9941 - val_loss: 0.0383 - val_accuracy: 0.9952\n",
      "Epoch 16/100\n",
      "1696/1696 [==============================] - 19s 11ms/sample - loss: 0.0367 - accuracy: 0.9941 - val_loss: 0.0561 - val_accuracy: 0.9952\n",
      "Epoch 17/100\n",
      "1696/1696 [==============================] - 18s 11ms/sample - loss: 0.0197 - accuracy: 0.9941 - val_loss: 0.1048 - val_accuracy: 0.9808\n",
      "Epoch 18/100\n",
      "1696/1696 [==============================] - 17s 10ms/sample - loss: 0.0220 - accuracy: 0.9947 - val_loss: 0.0466 - val_accuracy: 0.9952\n",
      "Epoch 19/100\n",
      "1696/1696 [==============================] - 20s 12ms/sample - loss: 0.0243 - accuracy: 0.9959 - val_loss: 0.4974 - val_accuracy: 0.9543\n",
      "Epoch 20/100\n",
      "1696/1696 [==============================] - 21s 12ms/sample - loss: 0.0087 - accuracy: 0.9988 - val_loss: 0.0094 - val_accuracy: 0.9952\n",
      "Epoch 21/100\n",
      "1696/1696 [==============================] - 23s 14ms/sample - loss: 0.0227 - accuracy: 0.9953 - val_loss: 0.0908 - val_accuracy: 0.9904\n",
      "Epoch 22/100\n",
      "1696/1696 [==============================] - 22s 13ms/sample - loss: 0.0366 - accuracy: 0.9953 - val_loss: 0.0191 - val_accuracy: 0.9952\n",
      "Epoch 23/100\n",
      "1696/1696 [==============================] - 21s 13ms/sample - loss: 0.0114 - accuracy: 0.9976 - val_loss: 0.0212 - val_accuracy: 0.9928\n",
      "Epoch 24/100\n",
      "1696/1696 [==============================] - 20s 12ms/sample - loss: 0.0185 - accuracy: 0.9947 - val_loss: 0.1239 - val_accuracy: 0.9904\n",
      "Epoch 25/100\n",
      "1696/1696 [==============================] - 21s 12ms/sample - loss: 0.0256 - accuracy: 0.9941 - val_loss: 0.0942 - val_accuracy: 0.9928\n",
      "Epoch 26/100\n",
      "1696/1696 [==============================] - 21s 13ms/sample - loss: 0.0126 - accuracy: 0.9976 - val_loss: 0.0479 - val_accuracy: 0.9952\n",
      "Epoch 27/100\n",
      "1696/1696 [==============================] - 17s 10ms/sample - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.0173 - val_accuracy: 0.9952\n",
      "Epoch 28/100\n",
      "1696/1696 [==============================] - 18s 10ms/sample - loss: 0.0149 - accuracy: 0.9965 - val_loss: 0.0209 - val_accuracy: 0.9952\n",
      "Epoch 29/100\n",
      "1696/1696 [==============================] - 20s 12ms/sample - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.2556 - val_accuracy: 0.9808\n",
      "Epoch 30/100\n",
      "1696/1696 [==============================] - 17s 10ms/sample - loss: 0.0064 - accuracy: 0.9976 - val_loss: 0.0555 - val_accuracy: 0.9952\n"
     ]
    }
   ],
   "source": [
    "# On entraine le modèle 3:\n",
    "\n",
    "history3 = model_top3.fit(train_features, train_labels,\n",
    "        epochs=epochs, \n",
    "        callbacks=my_callbacks,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la generation optimale est :  20\n"
     ]
    }
   ],
   "source": [
    "n_epochs = len(history3.history['loss'])\n",
    "print(\"la generation optimale est : \",n_epochs-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de l'entrainement : \n",
    "\n",
    "epochs = range(1,11)\n",
    "plt.plot(epochs, history1.history['accuracy'], label='Accuracy')\n",
    "plt.plot(epochs, history1.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.plot(epochs, history1.history['loss'], label='Loss')\n",
    "plt.plot(epochs, history1.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation loss and accuracy for the light layer fully connected')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Values')\n",
    "plt.show()\n",
    "\n",
    "epochs = range(1,11)\n",
    "plt.plot(epochs, history2.history['accuracy'], label='Accuracy')\n",
    "plt.plot(epochs, history2.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.plot(epochs, history2.history['loss'], label='Loss')\n",
    "plt.plot(epochs, history2.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation loss and accuracy for the medium layer fully connected')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Values')\n",
    "plt.show()\n",
    "\n",
    "epochs = range(1,11)\n",
    "plt.plot(epochs, history3.history['accuracy'], label='Accuracy')\n",
    "plt.plot(epochs, history3.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.plot(epochs, history3.history['loss'], label='Loss')\n",
    "plt.plot(epochs, history3.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation loss and accuracy for the heavy layer fully connected')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On evalue :\n",
    "\n",
    "# Avec les donnes de validation :\n",
    "\n",
    "eval1 = model_top1.evaluate(validation_features, validation_labels,verbose=2)\n",
    "eval2 = model_top2.evaluate(validation_features, validation_labels,verbose=2)\n",
    "eval3 = model_top3.evaluate(validation_features, validation_labels,verbose=2)\n",
    "\n",
    "# Avec les donnes de test :\n",
    "\n",
    "# On prend quelques exemples aleatoires :\n",
    "\n",
    "    # on visualise, on test , on affiche :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On reproduit le processus puis on compare :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enregistrements (facultatifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On enregistre le poids du model (eventuel) :\n",
    "model_top1.save_weights('../memory/Weights/dense121_lightTop_224_224_10G.h5')\n",
    "model_top2.save_weights('../memory/Weights/dense121_mediumTop_224_224_10G.h5')\n",
    "model_top3.save_weights('../memory/Weights/dense121_heavyTop_224_224_10G.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On enregistre le modele en entier:\n",
    "\n",
    "model_top3.save(\"../memory/FullModels/dense121_heavyTop_224_224_10G\")\n",
    "model_top2.save(\"../memory/FullModels/dense121_mediumTop_224_224_10G\")\n",
    "model_top1.save(\"../memory/FullModels/dense121_lightTop_224_224_10G\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #On enregistre l'historique:\n",
    "np.save('../memory/history/historique_chourouk_dense121_224_224_light_10G.npy',history1.history)\n",
    "np.save('../memory/history/historique_chourouk_dense121_224_224_medium_10G.npy',history2.history)\n",
    "np.save('../memory/history/historique_chourouk_dense121_224_224_heavy_10G.npy',history3.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
