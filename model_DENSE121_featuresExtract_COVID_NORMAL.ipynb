{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle pre-entrainer DENSE121 : classification binaire COVID / SAIN (NORMAL) par extraction de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des modules necessaire :\n",
    "\n",
    "import os\n",
    "\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 460 images d'entrainement de patient covid.\n",
      "Il y a 1266 images d'entrainement de patient non-covid.\n",
      "Il y a 116 images test de patient covid.\n",
      "Il y a 317 images test de patient non-covid.\n"
     ]
    }
   ],
   "source": [
    "# On declare les chemins vers les donnees :\n",
    "\n",
    "trainDir = 'Data/TRAIN'\n",
    "validationDir = 'Data/TEST'\n",
    " \n",
    "# On declare les dimensions pour les images (224,224) :\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "# On liste et stocke les chemins des images :\n",
    "ImageTRAINCOVID = os.listdir(trainDir + '/COVID')\n",
    "ImageTRAINNORMAL = os.listdir(trainDir + '/NORMAL')\n",
    "\n",
    "ImageTESTCOVID = os.listdir(validationDir + '/COVID')\n",
    "ImageTESTNORMAL = os.listdir(validationDir + '/NORMAL')\n",
    "\n",
    "# On affiche le nombre d'image trouve :\n",
    "print('Il y a ' + str(len(ImageTRAINCOVID)) + ' images d\\'entrainement de patient covid.') \n",
    "print('Il y a ' + str(len(ImageTRAINNORMAL)) + ' images d\\'entrainement de patient non-covid.') \n",
    "print('Il y a ' + str(len(ImageTESTCOVID)) + ' images test de patient covid.') \n",
    "print('Il y a ' + str(len(ImageTESTNORMAL)) + ' images test de patient non-covid.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de 6 exemples en 2 lignes et 3 colonnes pour chaque classe :\n",
    "\n",
    "# TRAIN :\n",
    "\n",
    "print(\"TRAIN COVID\")\n",
    "\n",
    "\n",
    "# COVID  :\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    randomImageTRAINCOVID = random.choice(os.listdir(trainDir + '/COVID'))\n",
    "    plt.imshow(plt.imread(os.path.join( trainDir +'/COVID',randomImageTRAINCOVID)), cmap='gray')\n",
    "    plt.title(randomImageTRAINCOVID)\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "print(\"TEST COVID\")\n",
    "# COVID  :\n",
    "plt.figure(figsize=(20,10))\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    randomImageTESTCOVID = random.choice(os.listdir(validationDir + '/COVID'))\n",
    "    plt.imshow(plt.imread(os.path.join( validationDir +'/COVID',randomImageTESTCOVID)), cmap='gray')\n",
    "    plt.title(randomImageTESTCOVID)\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "print(\"TRAIN NORMAL\")\n",
    "# NORMAL :\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    randomImageTRAINNORMAL = random.choice(os.listdir(trainDir + '/NORMAL'))\n",
    "    plt.imshow(plt.imread(os.path.join( trainDir +'/NORMAL',randomImageTRAINNORMAL)), cmap='gray')\n",
    "    plt.title(randomImageTRAINNORMAL)\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "\n",
    "# TEST:\n",
    "\n",
    "print(\"TEST NORMAL\")\n",
    "\n",
    "# NORMAL :\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    randomImageTESTNORMAL = random.choice(os.listdir(validationDir + '/NORMAL'))\n",
    "    plt.imshow(plt.imread(os.path.join(validationDir +'/NORMAL',randomImageTESTNORMAL)), cmap='gray')\n",
    "    plt.title(randomImageTESTNORMAL)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1726 images belonging to 2 classes.\n",
      "Found 433 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing :\n",
    "# On rescale les images :\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# On definit la batch size :\n",
    "batch_size = 32\n",
    "\n",
    "# On prepare les tableaux de donnees depuis les images :\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        trainDir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        validationDir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement de DENSE121 sans la partie fully-connected avec le reseau convolutif :\n",
    "\n",
    "model_dense = applications.DenseNet121(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On utilse le model VGG16 pour extraire les features de nos images \n",
    "# (on fait recupere la sortie du reseau convolutionnel) :\n",
    "train_features = model_dense.predict_generator(train_generator, 1726 // batch_size)\n",
    "\n",
    "validation_features = model_dense.predict_generator(validation_generator, 433 // batch_size)\n",
    "\n",
    "# L'opération étant longue on enregistre les features obtenus :\n",
    "np.save(open('models/trainFeatures_DENSE121_AllData.npy', 'wb'), train_features) # ecriture en binaire necessaire\n",
    "np.save(open('models/validationFeatures_DENSE121_AllData.npy', 'wb'), validation_features) # Idem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si l'operation à deja été effectuer on charge les features :\n",
    "\n",
    "train_features = np.load(open('models/trainFeatures_DENSE121_AllData.npy', 'rb'))\n",
    "validation_features = np.load(open('models/validationFeatures_DENSE121_AllData.npy', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On definit les labels :\n",
    "\n",
    "train_labels = np.array([0] * 448 + [1] * 1248)\n",
    "\n",
    "validation_labels = np.array([0] * 116 + [1] * 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On peut maintenat tester plusieurs couches fully-connected à partir de ce modele :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                3211328   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 3,211,393\n",
      "Trainable params: 3,211,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Premier modele : \n",
    "model_top1 = Sequential()\n",
    "model_top1.add(Flatten(input_shape=train_features.shape[1:]))\n",
    "model_top1.add(Dense(64, activation='relu'))\n",
    "model_top1.add(Dropout(0.5))\n",
    "model_top1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# On compile :\n",
    "model_top1.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# On affiche :\n",
    "model_top1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               6422656   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 6,422,785\n",
      "Trainable params: 6,422,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Second modele :\n",
    "model_top2 = Sequential()\n",
    "model_top2.add(Flatten(input_shape=train_features.shape[1:]))\n",
    "model_top2.add(Dense(128, activation='relu'))\n",
    "model_top2.add(Dropout(0.5))\n",
    "model_top2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# On compile :\n",
    "model_top2.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# On affiche :\n",
    "model_top2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               12845312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 12,845,569\n",
      "Trainable params: 12,845,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Troisieme modele :\n",
    "model_top3 = Sequential()\n",
    "model_top3.add(Flatten(input_shape=train_features.shape[1:]))\n",
    "model_top3.add(Dense(256, activation='relu'))\n",
    "model_top3.add(Dropout(0.5))\n",
    "model_top3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# On compile :\n",
    "model_top3.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# On affiche :\n",
    "model_top3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On definit les parametres pour l'entrainement :\n",
    "epochs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1696 samples, validate on 416 samples\n",
      "Epoch 1/10\n",
      "1696/1696 [==============================] - 8s 5ms/sample - loss: 1.6284 - accuracy: 0.9251 - val_loss: 0.0300 - val_accuracy: 0.9904\n",
      "Epoch 2/10\n",
      "1696/1696 [==============================] - 5s 3ms/sample - loss: 0.2184 - accuracy: 0.9623 - val_loss: 0.0303 - val_accuracy: 0.9904\n",
      "Epoch 3/10\n",
      "1696/1696 [==============================] - 5s 3ms/sample - loss: 0.1703 - accuracy: 0.9729 - val_loss: 0.2286 - val_accuracy: 0.9543\n",
      "Epoch 4/10\n",
      "1696/1696 [==============================] - 5s 3ms/sample - loss: 0.1483 - accuracy: 0.9782 - val_loss: 0.0261 - val_accuracy: 0.9904\n",
      "Epoch 5/10\n",
      "1696/1696 [==============================] - 5s 3ms/sample - loss: 0.0731 - accuracy: 0.9835 - val_loss: 0.0221 - val_accuracy: 0.9928\n",
      "Epoch 6/10\n",
      "1696/1696 [==============================] - 5s 3ms/sample - loss: 0.0840 - accuracy: 0.9829 - val_loss: 0.0221 - val_accuracy: 0.9928\n",
      "Epoch 7/10\n",
      "1696/1696 [==============================] - 5s 3ms/sample - loss: 0.1026 - accuracy: 0.9800 - val_loss: 0.0313 - val_accuracy: 0.9928\n",
      "Epoch 8/10\n",
      "1696/1696 [==============================] - 5s 3ms/sample - loss: 0.1068 - accuracy: 0.9835 - val_loss: 0.0390 - val_accuracy: 0.9952\n",
      "Epoch 9/10\n",
      "1696/1696 [==============================] - 5s 3ms/sample - loss: 0.0802 - accuracy: 0.9847 - val_loss: 0.0161 - val_accuracy: 0.9928\n",
      "Epoch 10/10\n",
      "1696/1696 [==============================] - 5s 3ms/sample - loss: 0.0571 - accuracy: 0.9864 - val_loss: 0.0557 - val_accuracy: 0.9904\n"
     ]
    }
   ],
   "source": [
    "# On entraine le modèle 1 :\n",
    "\n",
    "history1 = model_top1.fit(train_features, train_labels,\n",
    "        epochs=epochs, \n",
    "        batch_size=batch_size,\n",
    "        validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1696 samples, validate on 416 samples\n",
      "Epoch 1/10\n",
      "1696/1696 [==============================] - 11s 6ms/sample - loss: 4.3876 - accuracy: 0.9186 - val_loss: 0.0819 - val_accuracy: 0.9904\n",
      "Epoch 2/10\n",
      "1696/1696 [==============================] - 12s 7ms/sample - loss: 0.2456 - accuracy: 0.9729 - val_loss: 0.0287 - val_accuracy: 0.9928\n",
      "Epoch 3/10\n",
      "1696/1696 [==============================] - 11s 6ms/sample - loss: 0.2345 - accuracy: 0.9688 - val_loss: 0.0438 - val_accuracy: 0.9904\n",
      "Epoch 4/10\n",
      "1696/1696 [==============================] - 9s 5ms/sample - loss: 0.1758 - accuracy: 0.9652 - val_loss: 0.0281 - val_accuracy: 0.9928\n",
      "Epoch 5/10\n",
      "1696/1696 [==============================] - 10s 6ms/sample - loss: 0.0774 - accuracy: 0.9811 - val_loss: 0.0475 - val_accuracy: 0.9880\n",
      "Epoch 6/10\n",
      "1696/1696 [==============================] - 9s 5ms/sample - loss: 0.1095 - accuracy: 0.9788 - val_loss: 0.1491 - val_accuracy: 0.9712\n",
      "Epoch 7/10\n",
      "1696/1696 [==============================] - 10s 6ms/sample - loss: 0.1048 - accuracy: 0.9805 - val_loss: 0.0311 - val_accuracy: 0.9904\n",
      "Epoch 8/10\n",
      "1696/1696 [==============================] - 10s 6ms/sample - loss: 0.0765 - accuracy: 0.9870 - val_loss: 0.1032 - val_accuracy: 0.9784\n",
      "Epoch 9/10\n",
      "1696/1696 [==============================] - 9s 5ms/sample - loss: 0.0932 - accuracy: 0.9853 - val_loss: 0.0502 - val_accuracy: 0.9880\n",
      "Epoch 10/10\n",
      "1696/1696 [==============================] - 8s 5ms/sample - loss: 0.0490 - accuracy: 0.9888 - val_loss: 0.0862 - val_accuracy: 0.9808\n"
     ]
    }
   ],
   "source": [
    "# On entraine le modèle 2:\n",
    "\n",
    "history2 = model_top2.fit(train_features, train_labels,\n",
    "        epochs=epochs, \n",
    "        batch_size=batch_size,\n",
    "        validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1696 samples, validate on 416 samples\n",
      "Epoch 1/10\n",
      "1696/1696 [==============================] - 17s 10ms/sample - loss: 3.8450 - accuracy: 0.9239 - val_loss: 0.1443 - val_accuracy: 0.9904\n",
      "Epoch 2/10\n",
      "1696/1696 [==============================] - 15s 9ms/sample - loss: 0.7802 - accuracy: 0.9629 - val_loss: 0.1913 - val_accuracy: 0.9880\n",
      "Epoch 3/10\n",
      "1696/1696 [==============================] - 15s 9ms/sample - loss: 0.3711 - accuracy: 0.9735 - val_loss: 0.1946 - val_accuracy: 0.9880\n",
      "Epoch 4/10\n",
      "1696/1696 [==============================] - 15s 9ms/sample - loss: 0.2285 - accuracy: 0.9782 - val_loss: 0.0657 - val_accuracy: 0.9904\n",
      "Epoch 5/10\n",
      "1696/1696 [==============================] - 15s 9ms/sample - loss: 0.1636 - accuracy: 0.9782 - val_loss: 0.0773 - val_accuracy: 0.9904\n",
      "Epoch 6/10\n",
      "1696/1696 [==============================] - 14s 8ms/sample - loss: 0.1802 - accuracy: 0.9805 - val_loss: 0.0827 - val_accuracy: 0.9928\n",
      "Epoch 7/10\n",
      "1696/1696 [==============================] - 16s 9ms/sample - loss: 0.1366 - accuracy: 0.9776 - val_loss: 0.1674 - val_accuracy: 0.9784\n",
      "Epoch 8/10\n",
      "1696/1696 [==============================] - 14s 9ms/sample - loss: 0.0873 - accuracy: 0.9841 - val_loss: 0.4841 - val_accuracy: 0.9351\n",
      "Epoch 9/10\n",
      "1696/1696 [==============================] - 15s 9ms/sample - loss: 0.0974 - accuracy: 0.9841 - val_loss: 0.0667 - val_accuracy: 0.9928\n",
      "Epoch 10/10\n",
      "1696/1696 [==============================] - 15s 9ms/sample - loss: 0.0548 - accuracy: 0.9906 - val_loss: 0.0438 - val_accuracy: 0.9904\n"
     ]
    }
   ],
   "source": [
    "# On entraine le modèle 3:\n",
    "\n",
    "history3 = model_top3.fit(train_features, train_labels,\n",
    "        epochs=epochs, \n",
    "        batch_size=batch_size,\n",
    "        validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de l'entrainement : \n",
    "\n",
    "print(history1.history.keys())\n",
    "print(history1.history['accuracy'])\n",
    "\n",
    "epochs = range(1,11)\n",
    "plt.plot(epochs, history1.history['accuracy'], label='Accuracy')\n",
    "plt.title('Training and Validation loss and accuracy')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Values')\n",
    "plt.show()\n",
    "\n",
    "#---\n",
    "\n",
    "epochs = range(1,51)\n",
    "plt.plot(epochs, history['loss'], label='Loss')\n",
    "plt.plot(epochs, history['val_loss'], label='Validation loss')\n",
    "plt.plot(epochs, history['acc'], label='Accuracy')\n",
    "plt.plot(epochs, history['val_acc'], label='Validation acc')\n",
    "plt.title('Training and Validation loss and accuracy')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416/1 - 0s - loss: 0.0278 - accuracy: 0.9904\n",
      "416/1 - 0s - loss: 0.0431 - accuracy: 0.9808\n",
      "416/1 - 0s - loss: 0.0219 - accuracy: 0.9904\n"
     ]
    }
   ],
   "source": [
    "# On evalue :\n",
    "\n",
    "# Avec les donnes de validation :\n",
    "\n",
    "eval1 = model_top1.evaluate(validation_features, validation_labels,verbose=2)\n",
    "eval2 = model_top2.evaluate(validation_features, validation_labels,verbose=2)\n",
    "eval3 = model_top3.evaluate(validation_features, validation_labels,verbose=2)\n",
    "\n",
    "# Avec les donnes de test :\n",
    "\n",
    "# On prend quelques exemples aleatoires :\n",
    "\n",
    "    # on visualise, on test , on affiche :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On reproduit le processus puis on compare :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On enregistre le model (eventuel) :\n",
    "model_top1.save_weights('models/dense121_lightTop_224_224_10G.h5')\n",
    "model_top2.save_weights('models/dense121_mediumTop_224_224_10G.h5')\n",
    "model_top3.save_weights('models/dense121_heavyTop_224_224_10G.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
